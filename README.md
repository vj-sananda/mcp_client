# ğŸš€ MCP Client with Gemini AI

[ğŸ“¢ Subscribe to The AI Language on YouTube!](https://youtube.com/@theailanguage?sub_confirmation=1)

Happy building, and donâ€™t forget to subscribe!  

---

**Table of Contents**
- [âœª Features](#-features)
- [á½6 Installation](#-installation)
- [ğŸ”‘ Setting Up the API Key](#-setting-up-the-api-key)
- [ğŸš€ Running the MCP Client](#-running-the-mcp-client)
- [ğŸ”§ How It Works](#-how-it-works)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ¯ Example](#-example)
- [ğŸŒŸ Contributing](#-contributing)
- [ğŸ® Tutorial Videos](#-tutorial-videos)

You now have **three different MCP client implementations** in this repo:

### â” Option 1: Legacy Client (with Gemini but without LangChain)
```bash
uv run client.py path/to/server.py
```

### â” Option 2: New LangChain Client (with Gemini + React Agent)
```bash
uv run langchain_mcp_client.py path/to/server.py
```

### â” Option 3: New LangChain Client (with Gemini + React Agent, Multi-Server Config)
```bash
uv run langchain_mcp_client_wconfig.py path/to/config.json
```

If you want to add preexisting MCP Servers, please refer to [this repository](https://github.com/modelcontextprotocol/servers).

Watch the multi-server tutorial video ğŸ‘‰ [https://youtu.be/nCnBWVv2uTA](https://youtu.be/nCnBWVv2uTA)

[![Multi-Server Tutorial Video](https://img.youtube.com/vi/nCnBWVv2uTA/maxresdefault.jpg)](https://youtu.be/nCnBWVv2uTA)

---

## âœª **Features**
âœ… Connects to an MCP server (Python or Node.js)  
âœ… Sends queries to **Google Gemini AI**  
âœ… Lets **Gemini call external tools** from the MCP server  
âœ… Executes MCP tool commands and **returns the results**  
âœ… (in progress) **Maintains conversation history**, so Gemini **remembers past queries**       

---

## ğŸ“¦ **Installation**

**1âƒ£ Install the required dependencies using `uv` (Universal Virtualenv):**
```bash
uv add mcp python-dotenv google-genai
```

**2âƒ£ Clone this repository:**
```bash
cd mcp-client-gemini
```

**3âƒ£ Set up the project and virtual environment:**
```bash
uv init mcp-client
cd mcp-client
uv venv
```

**4âƒ£ Activate the virtual environment:**
```bash
# On Windows:
.venv\Scripts\activate

# On MacOS/Linux:
source .venv/bin/activate
```

---

## ğŸ”‘ **Setting Up the API Key**

To use **Google Gemini AI**, you need an **API key**. Please go to [Google AI Studio](https://aistudio.google.com/prompts/new_chat). Please read their terms and conditions and other policies before obtaining and using the key.

**1âƒ£ Create a `.env` file:**
```bash
touch .env
```

**2âƒ£ Add your API key inside `.env`:**
```
GEMINI_API_KEY=your_api_key_here
GOOGLE_API_KEY=your_api_key_here
```

**3âƒ£ Make sure `.env` is ignored in Git:**
```bash
echo ".env" >> .gitignore
```

*Note:* If you're using the new LangChain client, you can also name the key `GOOGLE_API_KEY`. The client will automatically load it using `dotenv`.

---

## ğŸš€ **Running the MCP Client**

You now have **three different MCP client implementations** in this repo:

### â” Option 1: Legacy Client (Without LangChain)
```bash
uv run client.py path/to/server.py
```

### â” Option 2: New LangChain Client (with Gemini + React Agent)
```bash
uv run langchain_mcp_client.py path/to/server.py
```

### â” Option 3: New LangChain Client (with Gemini + React Agent, Multi-Server Config)
```bash
uv run langchain_mcp_client_wconfig.py
```

Watch the respective tutorial videos:  
Legacy Client Tutorial ğŸ‘‰ [https://youtu.be/GAPncIfnDwg](https://youtu.be/GAPncIfnDwg)  
LangChain Client Tutorial ğŸ‘‰ [https://youtu.be/hccNm88bk6w](https://youtu.be/hccNm88bk6w)  
Multi-Server LangChain Client Tutorial ğŸ‘‰ [https://youtu.be/nCnBWVv2uTA](https://youtu.be/nCnBWVv2uTA)

---

## ğŸ”§ **How It Works**

1âƒ£ You enter a query like:  
`Create a file named test.txt`

2âƒ£ The MCP client sends this to **Google Gemini AI**

3âƒ£ Gemini sees available MCP tools and calls the correct one (e.g. `run_command`)

4âƒ£ The MCP client executes the command via the server and returns the result

5âƒ£ Gemini responds with context-aware output and remembers previous interactions

---

## ğŸ“ **Project Structure**
```
mcp-client-gemini/
â”‚â€” client.py                        # Legacy MCP Client (without LangChain)
â”‚â€” langchain_mcp_client.py          # New MCP Client using LangChain & Gemini
â”‚â€” langchain_mcp_client_wconfig.py  # New LangChain Client with multi-server configuration support
â”‚â€” .env                             # Stores your Google Gemini API key
â”‚â€” README.md                        # This documentation
â”‚â€” requirements.txt                 # Optional dependency list
â”‚â€” .gitignore                       # To ignore .env and other files
â”‚â€” LICENSE                          # License file
```

---

## ğŸ¯ **Example**

Run with a terminal server:
```bash
uv run langchain_mcp_client.py ../../servers/terminal_server/terminal_server.py
```

Query:
```
create file notes.txt and write hello inside
```

Output:
```json
{
  "messages": [
    {
      "type": "HumanMessage",
      "content": "create file notes.txt and write hello inside"
    },
    {
      "type": "AIMessage",
      "content": "Sure! I will create notes.txt and add 'hello' inside it."
    }
  ]
}
```

---

## ğŸŒŸ **Contributing**

If you'd like to add more client versions to help people learn the same concepts, please consider contributing!  
âœ… Submit bug fixes or ideas  
âœ… Help improve documentation

Just fork this repo and submit a pull request.

---

## ğŸ® **Tutorial Videos**

ğŸ¥ Legacy MCP Client Tutorial  
ğŸ‘‰ [https://youtu.be/GAPncIfnDwg](https://youtu.be/GAPncIfnDwg)

ğŸ¥ LangChain + Gemini MCP Client Tutorial  
ğŸ‘‰ [https://youtu.be/hccNm88bk6w](https://youtu.be/hccNm88bk6w)

ğŸ¥ Multi-Server LangChain Client Tutorial  
ğŸ‘‰ [https://youtu.be/nCnBWVv2uTA](https://youtu.be/nCnBWVv2uTA)